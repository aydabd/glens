# Glens Development Guide

> For contributors and developers working on Glens

**Architecture**: See [diagrams/ARCHITECTURE.md](diagrams/ARCHITECTURE.md) for visual system design.

## Setup

```bash
# Clone and setup environment
git clone <repo>
cd glens
make setup          # Creates micromamba env and installs tools

# Activate environment
micromamba activate glens-dev

# Build and test
make build
make test
```

## Project Structure

```txt
cmd/                   # CLI commands
  ├── root.go         # Root command, config loading
  ├── analyze.go      # Main analysis logic
  └── models.go       # AI model management

pkg/
  ├── ai/            # AI model clients (OpenAI, Anthropic, Ollama, Google)
  ├── generator/     # Test generation and execution
  ├── github/        # GitHub API integration
  ├── parser/        # OpenAPI spec parsing
  └── reporter/      # Report generation (MD, HTML, JSON)

configs/             # Example configurations
docs/                # Documentation + diagrams
```

See the [File Structure Diagram](diagrams/ARCHITECTURE.md#file-structure) for visual representation.

## Development Workflow

```bash
# 1. Make changes
vim cmd/analyze.go

# 2. Format code
make fmt

# 3. Run tests
make test

# 4. Check for issues
make lint

# 5. Build
make build

# 6. Test locally
./build/glens analyze <spec-url>
```

## Code Principles

### Simplicity

- Choose the simplest solution
- Avoid premature optimization
- Keep functions small (<50 lines)

### Go Idioms

- Follow `gofmt` and `golint` standards
- Explicit error handling
- Use standard library when possible

### Maintenance

- Write self-documenting code
- Add comments only for complex logic
- Keep file structure flat

## Key Components

### GitHub Issue Creation (`cmd/analyze.go`)

**Critical Logic**: Issues created ONLY for real test failures

```go
// isRealTestFailure() distinguishes:
// - Real failures: Assertion errors, spec violations
// - Not failures: Connection errors, compilation errors

if isRealTestFailure(err, result) {
    githubClient.CreateEndpointIssue(...)
}
```

### AI Integration (`pkg/ai/`)

Each AI provider implements `AIClient` interface:

```go
type AIClient interface {
    GenerateTest(ctx context.Context, endpoint *parser.Endpoint) (string, string, error)
}
```

### Test Execution (`pkg/generator/`)

Tests are:

1. Generated by AI
2. Written to temp directory
3. Executed with `go test`
4. Results parsed and analyzed

## Adding Features

### New CLI Flag

```go
// cmd/analyze.go
analyzeCmd.Flags().String("new-flag", "default", "Description")
_ = viper.BindPFlag("config.key", analyzeCmd.Flags().Lookup("new-flag"))
```

### New AI Provider

1. Implement `AIClient` interface in `pkg/ai/`
2. Add to `NewManager()` in `pkg/ai/interfaces.go`
3. Update config example

### New Report Format

1. Implement in `pkg/reporter/`
2. Add format option to `GenerateReport()`
3. Update CLI flag

## Testing

### Unit Tests

```go
// Use table-driven tests
func TestFunction(t *testing.T) {
    tests := []struct {
        name    string
        input   Input
        want    Output
        wantErr bool
    }{
        {"case1", input1, output1, false},
        {"case2", input2, output2, true},
    }

    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            got, err := Function(tt.input)
            if tt.wantErr {
                require.Error(t, err)
                return
            }
            require.NoError(t, err)
            assert.Equal(t, tt.want, got)
        })
    }
}
```

### Integration Tests

```bash
# Test with real API
./build/glens analyze https://petstore3.swagger.io/api/v3/openapi.json \
  --create-issues=false \
  --op-id=getPetById
```

## Common Tasks

### Update Dependencies

```bash
make update-deps
```

### Run Linters

```bash
make lint
make security
```

### Generate Coverage

```bash
make test
# Open build/reports/coverage.html
```

### Profile Performance

```bash
make profile
go tool pprof build/profiles/cpu.prof
```

## Debugging

### Enable Debug Logging

```bash
./build/glens analyze <url> --debug --log-format=console
```

### Common Issues

#### Tests fail with "go: not found"

- Activate micromamba environment: `micromamba activate glens-dev`

#### Ollama connection errors

- Start server: `make ollama-serve`
- Check status: `make ollama-status`

#### GitHub API errors

- Verify token: `echo $GITHUB_TOKEN`
- Check permissions: Token needs `repo` scope

## Release Process

```bash
# 1. Update version
# 2. Run full test suite
make ci

# 3. Build for all platforms
make build-all

# 4. Create release
make release

# Artifacts in build/dist/
```

## Code Review Checklist

- [ ] Follows Go idioms
- [ ] Has tests for new functionality
- [ ] Updates docs if needed (rarely)
- [ ] Passes linters
- [ ] Error handling is explicit
- [ ] Functions are small and focused
- [ ] No premature optimization
- [ ] Minimal dependencies

## Documentation

**When to update docs:**

- CLI interface changes
- Configuration format changes
- Setup process changes

**When NOT to update docs:**

- Internal refactoring
- Bug fixes (unless behavior changes)
- Performance improvements

## Getting Help

- Check existing issues
- Run with `--debug`
- Review logs in `report.md`
- See `.claude.md` for AI assistant instructions

## Contributing

1. Keep it simple
2. Write tests
3. Follow Go conventions
4. Update docs only if necessary
5. Think long-term maintenance

## Useful Commands

```bash
make help           # Show all commands
make env            # Create/update environment
make shell          # Enter environment shell
make clean          # Clean build artifacts
make docs           # Generate documentation
make ci             # Run CI pipeline locally
```
